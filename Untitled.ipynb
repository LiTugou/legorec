{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5eca9e-5fff-4f55-b93c-29bb814b0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0-11\n",
      "OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 12 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 6 cores/socket x 2 threads/core (6 total cores)\n",
      "OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 0 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 2 maps to socket 0 core 1 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 3 maps to socket 0 core 1 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 4 maps to socket 0 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 5 maps to socket 0 core 2 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 6 maps to socket 0 core 4 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 7 maps to socket 0 core 4 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 8 maps to socket 0 core 5 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 9 maps to socket 0 core 5 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 10 maps to socket 0 core 6 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 11 maps to socket 0 core 6 thread 1 \n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 640886 thread 0 bound to OS proc set 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/litugou/Documents/program/tvsearch/base/hook.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litugou/Documents/program/tvsearch/base/hook.py:64: The name tf.train.CheckpointSaverHook is deprecated. Please use tf.estimator.CheckpointSaverHook instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from base.options import FLAGS,Options\n",
    "from base.features import FeatureConf\n",
    "from base.hook import CheckpointSaverHook\n",
    "\n",
    "if tf.__version__.split(\".\",1)[0] == \"1\":\n",
    "    from tensorflow.keras import layers\n",
    "    tf.data.AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
    "else:\n",
    "    print(tf.__version__.split(\".\",1)[0])\n",
    "    from tensorflow.keras import layers\n",
    "    tf.truncated_normal_initializer=tf.compat.v1.truncated_normal_initializer\n",
    "    tf.feature_column.shared_embedding_columns=tf.feature_column.shared_embeddings\n",
    "    tf.feature_column.input_layer=tf.compat.v1.feature_column.input_layer\n",
    "    tf.losses.log_loss=tf.compat.v1.losses.log_loss\n",
    "    tf.metrics.auc=tf.compat.v1.losses.log_loss\n",
    "    tf.train.get_global_step=tf.compat.v1.train.get_global_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f773669e-6790-46f8-9546-eeef0d6063c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.mmoe import MMoE\n",
    "from layers.ppnet import PPNetBlock\n",
    "from layers.base import MLP,SELayer,FMCrossLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6328e0-7565-4a35-9997-17668d0b427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModel():\n",
    "    def __init__(self, opt):\n",
    "        self.opt=opt\n",
    "        feat_obj=FeatureConf(opt.feature_config_path,opt.feature_type_path,opt.KV_map_path,opt.field_emb_config_path)\n",
    "        self.feat_columns=feat_obj.feat_columns\n",
    "        self.feat_input=feat_obj.feat_input\n",
    "        self.feat_schema=feat_obj.feat_schema\n",
    "        self.feat_default=feat_obj.feat_default\n",
    "        \n",
    "        self.params={\n",
    "            'lr': self.opt.lr,\n",
    "            'min_lr': self.opt.min_lr,\n",
    "            'optimizer': self.opt.optimizer,\n",
    "            'max_train_step': self.opt.max_train_step,\n",
    "            'num_cross_layers': 4\n",
    "        }\n",
    "\n",
    "    def _build_optimizer(self, params, distribute=True):\n",
    "        return tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "\n",
    "        optim_type = params['optimizer'].lower()\n",
    "        max_train_step = params['max_train_step']\n",
    "\n",
    "        cur_step = tf.cast(tf.train.get_global_step(), tf.float32)\n",
    "        init_lr = params['lr']\n",
    "        min_lr = params['min_lr']\n",
    "        \n",
    "        cur_lr = init_lr - cur_step * (init_lr - min_lr) / (max_train_step - 1)\n",
    "\n",
    "        if optim_type == 'adam':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=cur_lr, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "        elif optim_type == 'adagrad':\n",
    "            optimizer = tf.train.AdagradOptimizer(learning_rate=cur_lr, initial_accumulator_value=1e-8)\n",
    "        elif optim_type == 'momentum':\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate=cur_lr, momentum=0.95)\n",
    "        elif optim_type == 'ftrl':\n",
    "            optimizer = tf.train.FtrlOptimizer(cur_lr)\n",
    "        else:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(cur_lr)\n",
    "\n",
    "        # SyncReplicasOptimizer for distribution\n",
    "        if distribute:\n",
    "            optimizer = tf.train.SyncReplicasOptimizer(optimizer,\n",
    "                                                       replicas_to_aggregate=self.opt.worker_num,\n",
    "                                                       total_num_replicas=self.opt.worker_num,\n",
    "                                                       use_locking=False, sparse_accumulator_type=\"multi_map\")\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def model_fn(self,features, labels, mode, params):\n",
    "        ### input\n",
    "        user_sparse_input = tf.feature_column.input_layer(features, self.feat_columns[\"user_sparse_column_list\"])\n",
    "        item_sparse_input = tf.feature_column.input_layer(features, self.feat_columns[\"item_sparse_column_list\"])\n",
    "        query_sparse_input = tf.feature_column.input_layer(features, self.feat_columns[\"query_sparse_column_list\"])\n",
    "        bias_sparse_input = tf.feature_column.input_layer(features, self.feat_columns[\"bias_sparse_column_list\"])\n",
    "        allemb=tf.concat([user_sparse_input,item_sparse_input,query_sparse_input],axis=1)\n",
    "        \n",
    "        sparse_num=len(self.feat_columns[\"user_sparse_column_list\"])+len(self.feat_columns[\"item_sparse_column_list\"])+len(self.feat_columns[\"query_sparse_column_list\"])\n",
    "\n",
    "    \n",
    "        allemb=SELayer([16])(tf.reshape(allemb,(-1,sparse_num,16)))\n",
    "        allemb=tf.reshape(allemb,(-1,16*sparse_num))\n",
    "        \n",
    "        # #ctr_emb,cvr_emb=MMoE(256,4,2)(allemb)\n",
    "        # ctr_fm=FMCrossLayer()(tf.reshape(allemb,(-1,sparse_num,16)))\n",
    "        # cvr_fm=FMCrossLayer()(tf.reshape(allemb,(-1,sparse_num,16)))\n",
    "\n",
    "        ctr_emb,cvr_emb=MMoE(4,[256],2,[128])(allemb)\n",
    "        # ctr_emb,cvr_emb=PLELayer(1,4,[256],2,[128],1)(allemb)\n",
    "        ## model\n",
    "        ctr=MLP(1,[256,128,64])(ctr_emb)\n",
    "        #ctr=ctr+ctr_fm\n",
    "        cvr=MLP(1,[256,128,64])(ctr_emb)\n",
    "        #cvr=cvr+cvr_fm\n",
    "        cvr_pred = tf.reshape(tf.sigmoid(cvr, name=\"cvr\"),[-1])\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            ctr_pred = tf.reshape(tf.sigmoid(ctr, name=\"ctr\"),[-1])\n",
    "\n",
    "            predictions = {\n",
    "                'ctr_pred': ctr_pred,\n",
    "                'cvr_pred': cvr_pred,\n",
    "            }\n",
    "            export_outputs = {'serving_default': tf.estimator.export.PredictOutput(predictions)}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
    "        \n",
    "        bias_ctr=MLP(1,[8,8])(bias_sparse_input)\n",
    "        bias_ctr=layers.Dropout(0.8)(bias_ctr)\n",
    "        # bias_ctr=tf.layers.dropout(bias_ctr, rate=0.8, training=True)\n",
    "        ctr_pred = tf.reshape(tf.sigmoid(ctr+bias_ctr, name=\"ctr\"),[-1])\n",
    "\n",
    "        ground_truth_ctr = tf.reshape(labels[\"ctr\"],[-1])\n",
    "        ground_truth_cvr = tf.reshape(labels[\"cvr\"],[-1])\n",
    "        loss1 = tf.reduce_mean(\n",
    "            tf.losses.log_loss(labels=ground_truth_ctr, predictions=ctr_pred))\n",
    "        ## 只使用点击样本\n",
    "        loss2 = tf.reduce_mean(\n",
    "            tf.losses.log_loss(labels=ground_truth_cvr, predictions=cvr_pred,\n",
    "                               weights=ground_truth_ctr+ground_truth_cvr*20))\n",
    "        # loss2 = tf.reduce_sum(\n",
    "        #     tf.losses.log_loss(labels=ground_truth_cvr, predictions=cvr_pred,\n",
    "        #                        weights=ground_truth_ctr))/tf.reduce_sum(ground_truth_ctr)\n",
    "        loss = loss1 + loss2\n",
    "        tf.add_to_collection('loss',loss)\n",
    "        tf.add_to_collection('loss1',loss1)\n",
    "        tf.add_to_collection('loss2',loss2)\n",
    "        \n",
    "        # eval\n",
    "        auc_ctr = tf.metrics.auc(labels=ground_truth_ctr, predictions=ctr_pred)\n",
    "        auc_cvr = tf.metrics.auc(labels=ground_truth_cvr, predictions=cvr_pred)\n",
    "\n",
    "        # tf.print(\"loss_ctr: \", loss1,\"  loss_cvr:\", loss2)\n",
    "        # print(\"auc_ctr\", auc_ctr[1],\"auc_cvr\", auc_cvr[1])\n",
    "        metrics = {'auc_ctr': auc_ctr,\"auc_cvr\":auc_cvr}\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        # train\n",
    "        optimizer = self._build_optimizer(params, distribute=self.opt.distribute)\n",
    "        \n",
    "        training_hooks=[]\n",
    "        training_chief_hooks=[]\n",
    "        \n",
    "        saver_hook = CheckpointSaverHook(checkpoint_dir=self.opt.output_dir,\n",
    "                                                       save_steps=self.opt.save_checkpoint_and_eval_step)\n",
    "        pos_cvr=tf.reduce_sum(ground_truth_cvr)\n",
    "        pos_ctr=tf.reduce_sum(ground_truth_ctr)\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"loss\":loss, \"loss1\": loss1, \"loss2\": loss2,\"auc_ctr\":auc_ctr[1],\"auc_cvr\":auc_cvr[1],\"pos_ctr\":pos_ctr,\"pos_cvr\":pos_cvr}, every_n_iter=100)\n",
    "        if self.opt.distribute:\n",
    "            print(\"hook_sync_replicas is set\")\n",
    "            self.hook_sync_replicas = optimizer.make_session_run_hook(is_chief=self.is_chief, num_tokens=0)\n",
    "            training_hooks.append(self.hook_sync_replicas)\n",
    "            training_chief_hooks.append(saver_hook)\n",
    "            training_chief_hooks.append(loggin_hook)\n",
    "        else:\n",
    "            training_hooks.append(logging_hook)\n",
    "            training_hooks.append(saver_hook)\n",
    "        # train_op = optimizer.minimize(loss)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        if self.opt.distribute:\n",
    "            self.sync_init_op = optimizer.get_init_tokens_op()\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op,\n",
    "                                          training_hooks=training_hooks,\n",
    "                                          training_chief_hooks=training_chief_hooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a83021d-47a5-46c6-8e42-e23c2fed491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS(sys.argv)\n",
    "opt=Options()\n",
    "modelobj=DeepModel(opt)\n",
    "feat_schema=modelobj.feat_schema\n",
    "# feat_schema[\"finalClickFlag\"]=tf.io.FixedLenFeature((), tf.float32)\n",
    "# feat_schema[\"pay_flag\"]=tf.io.FixedLenFeature((), tf.float32)\n",
    "feat_schema[\"finalClickFlag\"]=tf.io.FixedLenFeature((), tf.int64)\n",
    "feat_schema[\"pay_flag\"]=tf.io.FixedLenFeature((), tf.int64)\n",
    "\n",
    "feat_default=modelobj.feat_default\n",
    "feat_default[\"finalClickFlag\"]=0\n",
    "feat_default[\"pay_flag\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0759f4e-82d1-4eae-86bb-e95c33223ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/train/00.csv\",\"r\") as f:\n",
    "#     head=f.readline().strip()\n",
    "# column_names=head.split(\",\")\n",
    "# feat_all=modelobj.feat_default.keys()\n",
    "# for col in columns_names:\n",
    "#     if col not in feat_all:\n",
    "#         print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251fc33-13ee-4222-b4a3-abff77cfc729",
   "metadata": {},
   "source": [
    "### load from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d746bdf5-690c-4d2c-acc4-322256df9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataio import *\n",
    "\n",
    "train_list=glob.glob(\"./data/train/*.csv\")\n",
    "val_list=glob.glob(\"./data/val/*.csv\")\n",
    "test_list=glob.glob(\"./data/test/*.csv\")\n",
    "with open(\"data/train/00.csv\",\"r\") as f:\n",
    "        head=f.readline().strip()\n",
    "column_names=head.split(\",\")\n",
    "record_defaults=[feat_default.get(col,\"drop_value\") for col in column_names]\n",
    "drop_columns=[\"uid\",\"normslotmatchscore\",\"normtrunkmatchscore\"]\n",
    "\n",
    "# ds=input_fn(val_list,column_names,record_defaults,drop_columns,batch_size=1024)\n",
    "ds=input_fn(train_list,column_names,record_defaults,drop_columns,batch_size=1024)\n",
    "# batch=next(iter(ds.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2e9ba-21c6-47a5-94d5-d0bd8c1badfc",
   "metadata": {},
   "source": [
    "### load from tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1652e8d7-0c81-4ede-a85f-a763866377bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list=glob.glob(\"./data/train_tf/*.tf\")\n",
    "val_list=glob.glob(\"./data/val_tf/*.tf\")\n",
    "test_list=glob.glob(\"./data/test_tf/*.tf\")\n",
    "ds=loadtf(train_list,feat_schema,batch_size=64)\n",
    "# batch=next(iter(ds.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922342f-fbd3-4e26-9783-80298478edc3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af462784-bc57-4253-b723-0a7110ffc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './tmp_model', '_tf_random_seed': 2020, '_save_summary_steps': 500, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': 2000, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f76e25bef90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "opt.max_train_step=7400\n",
    "opt.output_dir=\"./tmp_model\"\n",
    "opt.save_summary_steps=500\n",
    "opt.save_checkpoint_and_eval_step=500\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=modelobj.model_fn,\n",
    "    params=modelobj.params,\n",
    "    config=tf.estimator.RunConfig(\n",
    "                model_dir=opt.output_dir,\n",
    "                tf_random_seed=2020,\n",
    "                save_summary_steps=opt.save_summary_steps,\n",
    "                save_checkpoints_steps=opt.save_checkpoint_and_eval_step,\n",
    "                keep_checkpoint_max=1000,\n",
    "                experimental_max_worker_delay_secs=2000)\n",
    ")\n",
    "\n",
    "# train_list=glob.glob(\"./data/train/*.csv\")\n",
    "# val_list=glob.glob(\"./data/val/*.csv\")\n",
    "# test_list=glob.glob(\"./data/test/*.csv\")\n",
    "\n",
    "# train_spec = tf.estimator.TrainSpec(\n",
    "#     input_fn=lambda: input_fn(train_list,column_names,record_defaults,drop_columns,batch_size=1024),\n",
    "#     max_steps=opt.max_train_step\n",
    "# )\n",
    "# eval_spec = tf.estimator.EvalSpec(\n",
    "#     input_fn=lambda: input_fn(val_list,column_names,record_defaults,drop_columns,batch_size=1024),\n",
    "#     steps=100,\n",
    "#     start_delay_secs=3,\n",
    "#     throttle_secs=3\n",
    "# )\n",
    "\n",
    "\n",
    "train_list=glob.glob(\"./data/train_tf/*.tf\")\n",
    "val_list=glob.glob(\"./data/val_tf/*.tf\")\n",
    "test_list=glob.glob(\"./data/test_tf/*.tf\")\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=lambda: loadtf(train_list,feat_schema,batch_size=1024),\n",
    "    max_steps=opt.max_train_step\n",
    ")\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda: loadtf(val_list,feat_schema,batch_size=1024),\n",
    "    steps=1000,\n",
    "    start_delay_secs=3,\n",
    "    throttle_secs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "163f9f03-a652-4857-b7ab-c1d705655352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 500 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:loss = 1.3862896, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641114 thread 4 bound to OS proc set 8\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641113 thread 1 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641317 thread 5 bound to OS proc set 10\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641318 thread 6 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641319 thread 7 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641320 thread 8 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641321 thread 9 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641322 thread 10 bound to OS proc set 9\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641323 thread 11 bound to OS proc set 11\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641324 thread 12 bound to OS proc set 0\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641325 thread 13 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641326 thread 14 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 640886 tid 641327 thread 15 bound to OS proc set 6\n",
      "INFO:tensorflow:loss = 1.3862896, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:auc_ctr = 0.5279784, auc_cvr = 1.0, loss = 1.3862896, loss1 = 0.6932492, loss2 = 0.6930403, pos_ctr = 519, pos_cvr = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:auc_ctr = 0.5279784, auc_cvr = 1.0, loss = 1.3862896, loss1 = 0.6932492, loss2 = 0.6930403, pos_ctr = 519, pos_cvr = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1260\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_640886/4232968579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1194\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m       logging.warning('Training with estimator made no steps. '\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m     \u001b[0;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[0;34m(self, exception_type)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session is already closed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         logging.warning(\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m         \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;31m# We intentionally suppress exceptions from the close() here since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         logging.warning(\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         logging.warning(\n",
      "\u001b[0;32m~/.conda/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_CloseSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66306d-0bcd-4c73-b4c0-ded6e90235b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.evaluate(input_fn=lambda :loadtf(val_list+test_list,feat_schema,num_epochs=1,batch_size=4096))\n",
    "\n",
    "# https://LiTugou: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@github.com/LiTugou/tvsearch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff25b72-48eb-4a8a-88c1-cce7849c20f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfv1",
   "language": "python",
   "name": "tfv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
